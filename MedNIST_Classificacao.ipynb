{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MedNIST_Classificacao.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lomurta/ProcImagens/blob/main/MedNIST_Classificacao.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeC6o5OMAFN7"
      },
      "source": [
        "# Classificação de imagens com o conjunto de dados MedNIST\n",
        "\n",
        "Introdução\n",
        "Neste tutorial, apresentamos um exemplo de treinamento e avaliação de ponta a ponta com base no conjunto de dados MedNIST.\n",
        "Passaremos pelos seguintes passos:\n",
        "\n",
        "- Crie um conjunto de dados MONAI para treinamento e teste\n",
        "- Use transformações MONAI para pré-processar dados\n",
        "- Use o DenseNet do MONAI para a tarefa de classificação\n",
        "- Treine o modelo com um programa PyTorch\n",
        "- Avaliar no conjunto de dados de teste\n",
        "\n",
        "### Obtenha o conjunto de dados\n",
        "O conjunto de dados do MedNIST foi coletado de vários conjuntos do [TCIA](https://wiki.cancerimagingarchive.net/display/Public/Data+Usage+Policies+and+Restrictions), [o RSNA Bone Age Challenge](http://rsnachallenges.cloudapp.net/competitions/4) e o [conjunto de dados de raios-X do tórax do NIH](https://cloud.google.com/healthcare/docs/resources/public-datasets/nih-chest).\n",
        "\n",
        "\n",
        "Os comandos a seguir baixam e descompactam o conjunto de dados (~60 MB)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZTNbFpgA6rX"
      },
      "source": [
        "!wget -q https://www.dropbox.com/s/5wwskxctvcxiuea/MedNIST.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyDZo_qaBEyn"
      },
      "source": [
        "# unzip the '.tar.gz' file to the current directory\n",
        "import tarfile\n",
        "datafile = tarfile.open(\"MedNIST.tar.gz\")\n",
        "datafile.extractall()\n",
        "datafile.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3rUPlOhBsnR"
      },
      "source": [
        "#Instalando o MONAI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRsBnGJeBJgW"
      },
      "source": [
        "!pip install -q \"monai-weekly[gdown, nibabel, tqdm, itk]\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ty_YA-cLBpyr"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "import tempfile\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from monai.apps import download_and_extract\n",
        "from monai.config import print_config\n",
        "from monai.metrics import ROCAUCMetric\n",
        "from monai.networks.nets import DenseNet121\n",
        "from monai.transforms import (\n",
        "    Activations,\n",
        "    AddChannel,\n",
        "    AsDiscrete,\n",
        "    Compose,\n",
        "    LoadImage,\n",
        "    RandFlip,\n",
        "    RandRotate,\n",
        "    RandZoom,\n",
        "    ScaleIntensity,\n",
        "    ToTensor,\n",
        ")\n",
        "from monai.data import Dataset, DataLoader\n",
        "from monai.utils import set_determinism\n",
        "\n",
        "print_config()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHhD_snaB70p"
      },
      "source": [
        "\n",
        "##Lendo nomes de arquivos de imagem das pastas do conjunto de dados\n",
        "Antes de mais nada, verifica os arquivos do conjunto de dados e mostra algumas estatísticas. Existem 6 pastas no conjunto de dados: Hand, AbdomenCT, CXR, ChestCT, BreastMRI, HeadCT, que devem ser usadas como rótulos para treinar nosso modelo de classificação."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaHFhidyCBJa"
      },
      "source": [
        "data_dir = './MedNIST/'\n",
        "class_names = sorted([x for x in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, x))])\n",
        "num_class = len(class_names)\n",
        "image_files = [[os.path.join(data_dir, class_name, x) \n",
        "                for x in os.listdir(os.path.join(data_dir, class_name))] \n",
        "               for class_name in class_names]\n",
        "image_file_list = []\n",
        "image_label_list = []\n",
        "for i, class_name in enumerate(class_names):\n",
        "    image_file_list.extend(image_files[i])\n",
        "    image_label_list.extend([i] * len(image_files[i]))\n",
        "num_total = len(image_label_list)\n",
        "image_width, image_height = Image.open(image_file_list[0]).size\n",
        "\n",
        "print('Total image count:', num_total)\n",
        "print(\"Image dimensions:\", image_width, \"x\", image_height)\n",
        "print(\"Label names:\", class_names)\n",
        "print(\"Label counts:\", [len(image_files[i]) for i in range(num_class)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KuPf7t-CFEV"
      },
      "source": [
        "## Visualizando alguns exemplos escolhidos aleatoriamente do conjunto de dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7kXrcmPCQPU"
      },
      "source": [
        "plt.subplots(3, 3, figsize=(8, 8))\n",
        "for i,k in enumerate(np.random.randint(num_total, size=9)):\n",
        "    im = Image.open(image_file_list[k])\n",
        "    arr = np.array(im)\n",
        "    plt.subplot(3, 3, i + 1)\n",
        "    plt.xlabel(class_names[image_label_list[k]])\n",
        "    plt.imshow(arr, cmap='gray', vmin=0, vmax=255)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkguefb6CTw5"
      },
      "source": [
        "## Preparando listas de dados de treinamento, validação e teste\n",
        "Selecionando aleatoriamente 10% do conjunto de dados como validação e 10% como teste."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuryrHlpCYfK"
      },
      "source": [
        "valid_frac, test_frac = 0.1, 0.1\n",
        "trainX, trainY = [], []\n",
        "valX, valY = [], []\n",
        "testX, testY = [], []\n",
        "\n",
        "for i in range(num_total):\n",
        "    rann = np.random.random()\n",
        "    if rann < valid_frac:\n",
        "        valX.append(image_file_list[i])\n",
        "        valY.append(image_label_list[i])\n",
        "    elif rann < test_frac + valid_frac:\n",
        "        testX.append(image_file_list[i])\n",
        "        testY.append(image_label_list[i])\n",
        "    else:\n",
        "        trainX.append(image_file_list[i])\n",
        "        trainY.append(image_label_list[i])\n",
        "\n",
        "print(\"Training count =\",len(trainX),\"Validation count =\", len(valX), \"Test count =\",len(testX))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJRqm8MNCbi4"
      },
      "source": [
        "## Definir transformações MONAI, Dataset e Dataloader para pré-processar os  dados de teste."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMsUgaYNCfrw"
      },
      "source": [
        "train_transforms = Compose([\n",
        "    LoadImage(image_only=True),\n",
        "    AddChannel(),\n",
        "    ScaleIntensity(),\n",
        "    RandRotate(range_x=15, prob=0.5, keep_size=True),\n",
        "    RandFlip(spatial_axis=0, prob=0.5),\n",
        "    RandZoom(min_zoom=0.9, max_zoom=1.1, prob=0.5, keep_size=True),\n",
        "    ToTensor()\n",
        "])\n",
        "\n",
        "val_transforms = Compose([\n",
        "    LoadImage(image_only=True),\n",
        "    AddChannel(),\n",
        "    ScaleIntensity(),\n",
        "    ToTensor()\n",
        "])\n",
        "\n",
        "act = Activations(softmax=True)\n",
        "to_onehot = AsDiscrete(to_onehot=True, n_classes=num_class)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJgCYleyCpTT"
      },
      "source": [
        "class MedNISTDataset(Dataset):\n",
        "\n",
        "    def __init__(self, image_files, labels, transforms):\n",
        "        self.image_files = image_files\n",
        "        self.labels = labels\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.transforms(self.image_files[index]), self.labels[index]\n",
        "\n",
        "train_ds = MedNISTDataset(trainX, trainY, train_transforms)\n",
        "train_loader = DataLoader(train_ds, batch_size=300, shuffle=True, num_workers=2)\n",
        "\n",
        "val_ds = MedNISTDataset(valX, valY, val_transforms)\n",
        "val_loader = DataLoader(val_ds, batch_size=300, num_workers=2)\n",
        "\n",
        "test_ds = MedNISTDataset(testX, testY, val_transforms)\n",
        "test_loader = DataLoader(test_ds, batch_size=300, num_workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmwtEGBbCtuL"
      },
      "source": [
        "## Definindo a rede e o otimizador\n",
        "1. Definindo a taxa de aprendizado para o quanto o modelo é atualizado por lote.\n",
        "2. Definindo o número de épocas total, pois misturamos sorteamos as transformações aleatórias, de modo que os dados de treinamento de cada época sejam diferentes.\n",
        "E como este é apenas um tutorial de introdução, vamos treinar 4 épocas.\n",
        "Se treinar 10 épocas, o modelo pode atingir 100% de precisão no conjunto de dados de teste.\n",
        "3. Usando o DenseNet do MONAI e mude para o dispositivo GPU, este DenseNet pode suportar tarefas de classificação 2D e 3D.\n",
        "4. Usando o otimizador Adam."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3efM0bwsC1wS"
      },
      "source": [
        "device = torch.device(\"cuda:0\")\n",
        "model = DenseNet121(\n",
        "    spatial_dims=2,\n",
        "    in_channels=1,\n",
        "    out_channels=num_class\n",
        ").to(device)\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), 1e-5)\n",
        "epoch_num = 4\n",
        "val_interval = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XpGqz_oDkXP"
      },
      "source": [
        "\n",
        "## Treinamento do modelo\n",
        "Executa um treinamento típico do PyTorch que roda o laço de época e laço de passo, e faz a validação após cada época.\n",
        "Salvará os pesos do modelo para arquivo se chegar à melhor acurácia de validação."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpKhLo3YDpXw"
      },
      "source": [
        "best_metric = -1\n",
        "best_metric_epoch = -1\n",
        "epoch_loss_values = list()\n",
        "auc_metric = ROCAUCMetric()\n",
        "metric_values = list()\n",
        "for epoch in range(epoch_num):\n",
        "    print('-' * 10)\n",
        "    print(f\"epoch {epoch + 1}/{epoch_num}\")\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    step = 0\n",
        "    for batch_data in train_loader:\n",
        "        step += 1\n",
        "        inputs, labels = batch_data[0].to(device), batch_data[1].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_function(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "        print(f\"{step}/{len(train_ds) // train_loader.batch_size}, train_loss: {loss.item():.4f}\")\n",
        "        epoch_len = len(train_ds) // train_loader.batch_size\n",
        "    epoch_loss /= step\n",
        "    epoch_loss_values.append(epoch_loss)\n",
        "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
        "\n",
        "    if (epoch + 1) % val_interval == 0:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            y_pred = torch.tensor([], dtype=torch.float32, device=device)\n",
        "            y = torch.tensor([], dtype=torch.long, device=device)\n",
        "            for val_data in val_loader:\n",
        "                val_images, val_labels = val_data[0].to(device), val_data[1].to(device)\n",
        "                y_pred = torch.cat([y_pred, model(val_images)], dim=0)\n",
        "                y = torch.cat([y, val_labels], dim=0)\n",
        "            y_onehot = [to_onehot(i) for i in y]\n",
        "            y_pred_act = [act(i) for i in y_pred]\n",
        "            auc_metric(y_pred_act, y_onehot)\n",
        "            auc_result = auc_metric.aggregate()\n",
        "            auc_metric.reset()\n",
        "            del y_pred_act, y_onehot\n",
        "            metric_values.append(auc_result)\n",
        "            acc_value = torch.eq(y_pred.argmax(dim=1), y)\n",
        "            acc_metric = acc_value.sum().item() / len(acc_value)\n",
        "            if acc_metric > best_metric:\n",
        "                best_metric = acc_metric\n",
        "                best_metric_epoch = epoch + 1\n",
        "                torch.save(model.state_dict(), 'best_metric_model.pth')\n",
        "                print('saved new best metric model')\n",
        "            print(f\"current epoch: {epoch + 1} current AUC: {auc_result:.4f}\"\n",
        "                  f\" current accuracy: {acc_metric:.4f} best AUC: {best_metric:.4f}\"\n",
        "                  f\" at epoch: {best_metric_epoch}\")\n",
        "print(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBDNC9--DtI8"
      },
      "source": [
        "## Plotando a perda e a métrica"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7P1BlRfsDuz4"
      },
      "source": [
        "plt.figure('train', (12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"Epoch Average Loss\")\n",
        "x = [i + 1 for i in range(len(epoch_loss_values))]\n",
        "y = epoch_loss_values\n",
        "plt.xlabel('epoch')\n",
        "plt.plot(x, y)\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"Validation: Area under the ROC curve\")\n",
        "x = [val_interval * (i + 1) for i in range(len(metric_values))]\n",
        "y = metric_values\n",
        "plt.xlabel('epoch')\n",
        "plt.plot(x, y)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hrx_mtTODyOe"
      },
      "source": [
        "## Avaliando o modelo na base de dados de teste\n",
        "Após treinamento e validação, já temos o melhor modelo no teste de validação.\n",
        "Precisamos validar o modelo na base de dados de teste para checar se o modelo está robusto e não há over-fitting.\n",
        "Usaremos estas predições para gerar um relatório de classificação."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHAA3LUxD2b6"
      },
      "source": [
        "model.load_state_dict(torch.load('best_metric_model.pth'))\n",
        "model.eval()\n",
        "y_true = list()\n",
        "y_pred = list()\n",
        "with torch.no_grad():\n",
        "    for test_data in test_loader:\n",
        "        test_images, test_labels = test_data[0].to(device), test_data[1].to(device)\n",
        "        pred = model(test_images).argmax(dim=1)\n",
        "        for i in range(len(pred)):\n",
        "            y_true.append(test_labels[i].item())\n",
        "            y_pred.append(pred[i].item())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOy8uzlwD8se"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_true, y_pred, target_names=class_names, digits=4))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}